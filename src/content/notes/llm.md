---
title: LLM
publishDate: 2024-10-16
---

# LLM

## Chinese LLM

- [使用繁體中文評測各家 Embedding 模型的檢索能力](https://ihower.tw/blog/archives/12167)

## Hallucination

It is a billion worth question, if someone tell you they want want any, reply with a firm "No".

- [Chain-of-verification paper](https://arxiv.org/pdf/2309.11495)

## N-shot learning

- [Zero-Shot Learning in Modern NLP](https://joeddav.github.io/blog/2020/05/29/ZSL.html)
- [Analytics Vidhya | Know about Zero Shot, One Shot and Few Shot Learning](https://www.analyticsvidhya.com/blog/2022/12/know-about-zero-shot-one-shot-and-few-shot-learning/)

## Resources

- [DataTalksClub/llm-zoomcamp](https://github.com/DataTalksClub/llm-zoomcamp)
- [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)
- [What We’ve Learned From A Year of Building with LLMs](https://applied-llms.org/)
- [从编解码和词嵌入开始，一步一步理解Transformer，注意力机制(Attention)的本质是卷积神经网络(CNN)](https://www.youtube.com/watch?v=GGLr-TtKguA)
- [Transformer论文逐段精读](https://www.youtube.com/watch?v=nzqlFIcCSWQ)
- [【生成式AI科普3】ChatGPT原理揭密！背后的黑科技Transformer | Demystify Transformer Behind ChatGPT](https://www.youtube.com/watch?v=nIncwp0iAkw)
- [RAG vs. Fine Tuning](https://www.youtube.com/watch?v=00Q0G84kq3M)
