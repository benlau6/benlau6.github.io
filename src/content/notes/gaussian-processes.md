---
title: Gaussian Processes
publishDate: 2024-09-20
---

# Gaussian Processes

## Introduction

For a given set of training points, there are potentially infinitely many functions that fit the data. Gaussian processes offer an elegant solution to this problem by assigning a probability to each of these functions. The mean of this probability distribution then represents the most probable characterization of the data. Furthermore, using a probabilistic approach allows us to incorporate the confidence of the prediction into the regression result. They also allow us to make predictions about our data by incorporating prior knowledge. [visual exploration](https://distill.pub/2019/visual-exploration-gaussian-processes/)

In order to set up the distribution, we need to define mean $\mu$ and covariance matrix $\Sigma$. In Gaussian processes, it is often assumed that $\mu=0$, which simplifies the necessary equations for conditioning, and this assumption could be easily achieved by centering the data. So the most important parameter is $\Sigma$, which determines the characteristics of a Gaussian process.

The covariance matrix is generated by the kernel function, which is often also called covariance function, pairwise on all the points. The choice of kernels are based on our prior beliefs. Kernels can be separated into stationary and non-stationary kernels. Stationary kernels, such as the RBF kernel or the periodic kernel, are functions invariant to translations, and the covariance of two points is only dependent on their relative position. Non-stationary kernels, such as the linear kernel, do not have this constraint and depend on an absolute location. Most importantly, kernels could be combined by addition or multiplication to form a new kernel, which is a powerful property to model complex data.

## Problems

GPs are generally a go-to approach for non-linear time series, but the reservation is that it is not a mechanistic model. So it is not good for modeling compartmental models such as SIR, SEIR, etc. A GP model might be useful for very short-term predictions, but since it does not account for changes in behavior (including specific interventions), it has limited use. That said, it might be interesting to incorporate a GP into a mechanistic model as a way of estimating some of the latent parameters, and their dynamics [1](https://discourse.pymc.io/t/prediction-of-danish-covid19-cases/4904).

However, there seems to be a solution [Stationarity without mean reversion in improper Gaussian processes](https://arxiv.org/pdf/2310.02877).

## Examples

- [Forecasting of CO2 level on Mona Loa using Gaussian Process regression](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_co2.html) [another blog on CO2](https://peterroelants.github.io/posts/gaussian-process-kernels/) [pymc example](https://www.pymc.io/projects/examples/en/latest/gaussian_processes/GP-MaunaLoa.html#the-model-in-pymc3) [pymc improved version](https://www.pymc.io/projects/examples/en/latest/gaussian_processes/GP-MaunaLoa2.html) [pymc discussion](https://discourse.pymc.io/t/gaussian-process-regression-level-1-inference-re-producing-mauna-loa-co2-example-with-pymc3/241/6)
- [An Introduction to Gaussian Process Regression](https://juanitorduz.github.io/gaussian_process_reg/)
- [PyData Berlin 2019: Gaussian Processes for Time Series Forecasting (scikit-learn)](https://juanitorduz.github.io/gaussian_process_time_series/)
- [Gaussian Processes for Time Series Forecasting with PyMC3](https://juanitorduz.github.io/gp_ts_pymc3/)
- [Time Series Modeling with HSGP: Baby Births Example](https://juanitorduz.github.io/birthdays/)

## Readings

- [A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/)
- [Scikit-Learn Example in PyMC: Gaussian Process Classifier](https://juanitorduz.github.io/sklearn_pymc_classifier/)
