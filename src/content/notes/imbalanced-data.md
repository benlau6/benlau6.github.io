---
title: Imbalanced Data
publishDate: 2024-10-03
---

# Imbalanced Data

## Metrics

Using accuracy, recall or precision will be problematic when the data is imbalanced because the model can blindly predict a single target label to be 100% accurate. Use F1 score while there is no clear preference between recall and precision, or use F-beta score when there is a preference, with beta being the weight of precision. When beta equals 1, it is the same as F1 score. [Accuracy, precision, and recall in multi-class classification](https://www.evidentlyai.com/classification-metrics/multi-class-metrics)

## Readings

- [7 Techniques to Handle Imbalanced Data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)
- [Bagging and Random Forest for Imbalanced Classification](https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/)
- [linkedin discussion](https://www.linkedin.com/posts/junaid-syed-2412631b4_ever-faced-this-tricky-data-science-interview-activity-7243438951565291520-a8Q3/?utm_source=share&utm_medium=member_desktop)
